\input{config.tex} % Les usepackage sont dans config.tex
\input{macros.tex} % Présentation d'O. Chabiron



\title{Optimisation de dictionnaires structurés en arbres de convolutions pour la représentation parcimonieuse d'images}
\subtitle{Stage encadrée par\\François Malgouyres (IMT), Jean-Yves Tourneret (IRIT-ENSEEIHT) et Herwig Wendt (CNRS-ENSEEIHT)}

\date{Soutenance de stage du 8 septembre 2016}
\author{Maël Valais}
%\institute{}

\begin{document}

\maketitle

\plain{Introduction : \\la représentation parcimonieuse}


\begin{frame}[label=LO]{La représentation parcimonieuse}
La \alert{représentation parcimonieuse} permet de débruiter, décrire, compresser, classifier
\todo[inline]{TODO: ajouter exemple image débruitée avec KSVD}
\end{frame}


\begin{frame}{Les dictionnaires}
Dictionnaire = opérateur permettant de passer d'une image à une représentation cible

\end{frame}


\begin{frame}{Dictionnaires génériques vs. appris}
\begin{description}
	\item[Dictionnaires génériques] cosinus (JPEG), Fourier, Wavelets, Curvelets
	\item[Dictionnaires appris] K-SVD
\end{description}
\end{frame}


\begin{frame}{Problème du coût de Dx}
Problème d'apprentissage de dictionnaire \eqref{eq_dl} pour apprendre un dictionnaire parcimonieux :
\begin{align} 
\underset{\D,\x}{\min}~ & \| \x \|_1 + \lambda \| \Req{\D\x}-\y \|^2_2 \tag{$DL$}\label{eq_dl} \\
\text{s.t.}~ & \| \d_k \| \le \gamma & \forall k = 1,\dots,K\label{eq_dl_finite_norm} \notag
\end{align}
\begin{description}
	\item[Problème] Coût élevé de $\D\x$ : \alert{$O(N^2)$}
	\item[Solution] Réduire la taille des images en entrée (patches dans KSVD)
	\item[Défaut] Les atomes ne peuvent pas représenter de grandes formes
\end{description}
\end{frame}


\begin{frame}{Motivations générales}
	\begin{itemize}
		\item développer une \alert{transformée rapide} adaptée aux grands atomes
		\item effectuer l'apprentissage \alert{directement sur l'image} au lieu des patches
	\end{itemize}
\end{frame}


\plain{Existant : \\Modèle d'arbre convolutionnel et PALMTREE}

\begin{frame}{Existant : le modèle d'arbres de convolutions}
\includegraphics[width=\textwidth]{figures/tree.pdf}

Ainsi, le produit $\D\x$ est réduit à

\begin{equation}
\D \x = \Req{\sum_{l \in ~\text{Feuilles}}} \x^{\Req{l}} * \underbrace{\h^{\Req{l}}* \dots* \h^{r}}_{\textrm{de la racine à la feuille}}
\end{equation}
soit une complexité en \alert{$O(N)$}

\end{frame}
 

\begin{frame}{Existant : problème associé}
On appelle \eqref{eq_ftl} (\alert{Fast Transform Learning}) l'adaptation de \eqref{eq_dl} à ce modèle :
\begin{equation*} {\small
\underset{\substack{(\h^\text{e})_{e \in \E}}}\min
	\norm{\Req{\sum_{l \in Feuilles}} \x^{\Req{l}} * \h^{*\Req{l}} -\y}{2}^2 \tag{${FTL}$} \label{eq_ftl}
    }
\end{equation*}
L'algorithme \alert{PALMTREE} donne une solution à ce problème :
\begin{itemize}
	\item algorithme itérant successivement sur les blocs de variables $\h^e$
	\item \cite{chabiron_optimization_2016} a montré que le point  critique atteint n'est pas trop éloigné du minimum global
\end{itemize}
\end{frame}


\begin{frame}{Existant : exemple issu de PALMTREE}
\begin{figure}[!ht]\centering
\begin{subfigure}[b]{0.30\textwidth}\centering
	\includegraphics[width=\textwidth]{figures-masters-thesis/tree-learn-setup/target.pdf}
	\caption{Image cible $\y$}
\end{subfigure}
\begin{subfigure}[b]{0.30\textwidth}\centering
	\includegraphics[width=\textwidth]{figures-masters-thesis/tree-learn-setup/xp_learnsupp256_curvelet_decomp3[tree-binary_dpth4]_supp-generic3x3_[fixed-supports]_tree.pdf}
		\caption{Supports des noyaux}
\end{subfigure}
\begin{subfigure}[b]{0.30\textwidth}\centering
	\includegraphics[width=\textwidth]{figures-masters-thesis/tree-learn-setup/codes.pdf}
	\caption{Quelques codes $\x^l$}
\end{subfigure}
\end{figure}
\end{frame}


\begin{frame}{Existant : résultats et défauts}
\begin{figure} \centering
\begin{subfigure}[b]{0.30\textwidth}\centering
	\includegraphics[width=\textwidth]{figures-masters-thesis/tree-learn-setup/xp_learnsupp256_curvelet_decomp3[tree-binary_dpth4]_supp-generic3x3_[fixed-supports]_approx.pdf}
\end{subfigure}
\begin{subfigure}[b]{0.30\textwidth}\centering
	\includegraphics[width=\textwidth]{figures-masters-thesis/tree-learn-setup/xp_learnsupp256_curvelet_decomp3[tree-binary_dpth4]_supp-generic3x3_[fixed-supports]_mothertree.pdf}
\end{subfigure}
\end{figure}
\end{frame}


\begin{frame}
	\frametitle{Objectifs du stage}
	Étudier la possibilité d'apprendre les supports à partir de l'image cible
\end{frame}


\plain{Travail réalisé}

\begin{frame}{L'idée}
\begin{itemize}
	\item Apprendre le support "à la OMP"
	\item Utiliser la direction de plus forte descente du gradient
\end{itemize}
Dans les faits, il a fallu
\begin{itemize}
	\item Vérifier que le gradient indique bien le meilleur élément à ajouter au support
	\item Vérifier que l'algo OMP-PALMTREE fonctionne sur un arbre
\end{itemize}
\end{frame}


\begin{frame}{Ajouter un élément au support avec le gradient?}
\end{frame}


\begin{frame}{OMP-PALMTREE sur une branche}
\end{frame}


\begin{frame}{OMP-PALMTREE sur un arbre}
Soucis
\begin{itemize}
	\item les éléments de chaque supports sont très éloignés les uns des autres
	\item la taille du support est déséquilibrée à travers l'arbre
\end{itemize}
\end{frame}


\begin{frame}{Régularisation}
\end{frame}


\begin{frame}{En quelques mots...}
\begin{itemize}
\item PALMTREE (existant) se base sur des arbres de convolutions
\item Passer des supports fixes (PALMTREE) à des supports appris (OMP-PALMTREE)
\item ...
\end{itemize}
\vfill
\hfill Merci de votre attention
\end{frame}

\appendix

\begin{frame}[allowframebreaks,noframenumbering]
\frametitle{Bibliographie}
%\nocite{}
\printbibliography[heading=none]
\end{frame}


\end{document}