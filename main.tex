\input{config.tex} % Les usepackage sont dans config.tex
\input{macros.tex} % 



\title{Optimisation de dictionnaires structurés en arbres de convolutions pour la représentation parcimonieuse d'images}
\subtitle{Stage encadré par\\François Malgouyres (IMT), Jean-Yves Tourneret (IRIT-ENSEEIHT) et Herwig Wendt (CNRS-ENSEEIHT)}



\date{Soutenance de stage du 8 septembre 2016}
\author{Maël Valais}
\institute{Université Toulouse III - Paul Sabatier}

\begin{document}

\maketitle


\section{Introduction}
\subsection{La représentation parcimonieuse}


\begin{frame}{La représentation parcimonieuse}
\begin{itemize}
\item La représentation parcimonieuse permet de débruiter, décrire, compresser, classifier
\item Exemple de débruitage en utilisant un dictionnaire de DCT sur une image bruitée :
	\begin{figure}\centering
	\makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/0-exple-denoise/exple-denoise.pdf}}
	\end{figure}
\end{itemize}
\end{frame}


\subsection{Dictionnaires}
\begin{frame}{Les dictionnaires}
\begin{itemize}
\item Un dictionnaire peut permettre de représenter parcimonieusement
\item Deux grands types de dictionnaires : générique et appris
	\begin{table}[] \centering
	\begin{tabular}{@{}lcc@{}} \toprule
	 & Rapide & Adaptatif \\ \midrule
	DCT (générique) & \cmark & \xmark\\
	K-SVD (appris) & \xmark & \cmark \\ \bottomrule
	\end{tabular}
	\end{table}
\end{itemize}
\end{frame}

\begin{frame}{Problème du coût de Dx}
Problème d'apprentissage de dictionnaire \eqref{eq_dl} pour apprendre un dictionnaire parcimonieux :
\begin{align} 
\underset{\D,\x}{\min}~ & \| \x \|_1 + \lambda \| \Beq{\D\x}-\y \|^2_2 \tag{$DL$}\label{eq_dl} \\
\text{s.t.}~ & \| \d_k \| \le \gamma & \forall k = 1,\dots,N|\L| \label{eq_dl_finite_norm} \notag
\end{align}
 avec $\y \in \R^N$ l'image sur laquelle on apprend, $\x \in \R^{N \times |\L|}$ le code, $|\L|$ et $|\E|$ les nombres de feuilles et d'arcs, et $\D$ la matrice de $N|\L| \times N$.
\begin{description}
	\item[Problème] \alert{Coût élevé} de $\D\x$ : $O(N^2)$
	\item[Solution] Réduire la taille des images en entrée (patches dans KSVD)
	\item[Défaut] Les atomes ne peuvent pas représenter de grandes formes
\end{description}
\end{frame}


\subsection{Motivations}
\begin{frame}{Motivations générales}
	\begin{itemize}
		\item développer une \alert{transformée rapide} adaptée aux grands atomes
		\item effectuer l'apprentissage \alert{directement sur l'image} au lieu des patches
	\end{itemize}
\end{frame}







\section{Existant}


\subsection{Modèle d'arbre de convolutions}


\begin{frame}{Le modèle d'arbres de convolutions}
\begin{figure}\centering
\makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/tree.pdf}}
\end{figure}
Ainsi, le produit $\D\x$ est réduit à
\begin{equation} 
\D \x = \Beq{\sum_{l \in ~\text{Feuilles}}} \x^{\Beq{l}} * \underbrace{\h^{\Beq{l}}* \dots* \h^{r}}_{\textrm{de la racine à la feuille}}
\end{equation}
soit une complexité en \alert{$O(NQ)$} au lieu de $O(N^2)$ ($Q$ est le nombre total d'éléments des supports $\s^e$ associés à chaque noyau $\h^e$)
\end{frame}
 

\begin{frame}{Problème associé}
On appelle \eqref{eq_ftl} (\emph{Fast Transform Learning}) l'adaptation de \eqref{eq_dl} à ce modèle :
\begin{equation*}
\min_{\substack{(\h^e)_{e \in \E} \\ \h^e \in \D^e}}
	\underbrace{\norm{\Beq{\sum_{l \in Feuilles}} \x^{\Beq{l}} * \h^{*\Beq{l}} -\y}{2}^2}_{\text{Fonction objectif } \alert{E(\h)}} \tag{${FTL}$} \label{eq_ftl}
\end{equation*}
avec $\D^e$ la contrainte sur les supports.
L'algorithme \emph{PALMTREE} donne une solution à ce problème :
\begin{itemize}
	\item algorithme proximal itérant successivement sur les blocs de variables $\h^e$
	\item \cite{chabiron_optimization_2016} a montré que le point  critique atteint n'est pas trop éloigné du minimum global
\end{itemize}
\end{frame}

\subsection{L'algorithme PALMTREE}
\begin{frame}{Exemple de solution de PALMTREE}
\textbf{Entrées :} \begin{itemize}
	\item image $\y$,
	\item code $\x$ (un code $\x^l \in \R^N$ par feuille)
	\item supports $\s^e$, arbre $\T$
\end{itemize}
\begin{figure}\centering
\makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/1-intro-tree/intro-inputs.pdf}}
\end{figure}
\end{frame}


\begin{frame}{Exemple de solution de PALMTREE}
\textbf{Sortie :} les noyaux $\h$ (on note $\h = (\h^e)_{e \in \E}$)
\begin{figure}\centering
\makebox[\linewidth]{\includegraphics[width=1\linewidth]{figures/1-intro-tree/intro-outputs.pdf}}
\end{figure}
\end{frame}


\subsection{Objectifs du stage}
\begin{frame}{Objectifs du stage}
\begin{alertblock}{Inconvénients de PALMTREE}
\begin{itemize}
\item Supports fixes = perte d'adaptabilité
\item Arbre fixe
\end{itemize}
\end{alertblock}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=0.9\linewidth]{figures/meilleur-atome.pdf}}
\end{figure}
\begin{exampleblock}{Objectifs du stage}
Apprendre les supports à partir de l'image $\y$
\end{exampleblock}
\end{frame}




\section{Travail réalisé}

\subsection{Idée directrice inspirée de l'OMP}
\begin{frame}{L'idée}
\begin{block}{Algorithme OMP (Orthogonal Matching Pursuit)}
	\begin{enumerate}
		\item \textbf{Chercher} meilleur élément à ajouter au support
		\item Ajouter l'élément
		\item \textbf{Projeter} orthogonalement pour prendre en compte l'ajout
		\item Recommencer jusqu'à ce que le support soit assez grand
	\end{enumerate}
\end{block}
\begin{itemize}
\item \textbf{Pour chercher :} direction de plus forte descente (gradient)
\item \textbf{Pour projeter :} utiliser PALMTREE
\end{itemize}
\begin{exampleblock}{Questionnements}
\begin{itemize}
	\item Gradient convenable pour ajouter le meilleur élément possible ?
	\item Cet algorithme fonctionne t-il dans le cadre d'un arbre ?
\end{itemize}
\end{exampleblock}
\end{frame}


\subsection{Gradient convenable pour ajouter des élément ?}

\begin{frame}{Explications des expériences sur le gradient}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/2-check-gradient/branche-setup.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Gain versus gradient}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/2-check-gradient/gradient-vs-gain.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Résultats après ajout}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.0\linewidth]{figures/2-check-gradient/apres-ajout.pdf}}
\end{figure}
\end{frame}

\subsection{Ça fonctionne sur un arbre ?}

\begin{frame}{Explication des expériences sur un arbre}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.0\linewidth]{figures/3-learn-tree-scattered/learn-inputs.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Détail algorithme OMP-PALMTREE}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/3-learn-tree-scattered/algo-omp-palmtree.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Problème des supports dispersés}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/3-learn-tree-scattered/scattered-tree.pdf}}
\end{figure}
\begin{alertblock}{Problème d'identifiabilité des atomes}
Un atome avec 16 morceaux dispersés \alert{ou} 16 atomes bien séparés ?
\end{alertblock}
\end{frame}

\begin{frame}{Ajout d'un à priori sur les supports}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/3-learn-tree-scattered/scattered-explication.pdf}}
\end{figure}
\end{frame}


\begin{frame}{À priori $f$}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=0.8\linewidth]{figures/3-learn-tree-scattered/unscattered.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Réglage de $\alpha$}
\begin{itemize}
\item Nous avons déterminé $\alpha$ au cas par cas
	\begin{figure}\centering
	    \makebox[\linewidth]{\includegraphics[width=0.8\linewidth]{figures/3-learn-tree-scattered/alpha.pdf}}
	\end{figure}
\item Déterminer $\alpha$ pendant OMP-PALMTREE : méthode SURE \cite{eldar_generalized_2009} ?
\end{itemize}
\end{frame}

\begin{frame}{Problème de déséquilibre avec à priori $f$}
\begin{itemize}
\item \alert{Déséquilibre :} 55 éléments au centre, 3 élément sur les feuilles
	\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1\linewidth]{figures/4-learn-tree-unbalanced/unbalanced.pdf}}
	\end{figure}
\item Trop d'éléments au centre $\rightarrow$ convolutions lentes (lié à l'implémentation)
\item Adapter $f(p)$ en fonction de l'arc $e$ ?

\end{itemize}
\end{frame}



\begin{frame}{Modification de la fonction d'à priori $f$ pour équilibrer}
\begin{figure}\centering
    \makebox[\linewidth]{\includegraphics[width=1.1\linewidth]{figures/4-learn-tree-unbalanced/essai.pdf}}
\end{figure}
\end{frame}


\begin{frame}{Conclusions}
Jusqu'ici, nous avons
\begin{itemize}
\item[\cmark] Gradient validé pour choisir le meilleur élément à ajouter
\item[\cmark] Proposition d'un à priori pour apprendre les supports sur un arbre
\end{itemize}
Dans le futur proche
\begin{itemize}
\item Apprendre $\alpha$ à partir des données
\item Permettre la suppression d'éléments du support (norme $l_1$ ?)
\end{itemize}
Dans le futur plus lointain
\begin{itemize}
\item[\textcolor{purple}{\ding{43}}] Apprendre l'arbre (aujourd'hui, arbre fixé à la main)
\item[\textcolor{purple}{\ding{43}}] Apprendre sur plusieurs images
\item[\textcolor{purple}{\ding{43}}] Passer à un algorithme d'apprentissage de dictionnaire complet
\end{itemize}
\vfill
\hfill Merci de votre attention
\end{frame}

\appendix

\begin{frame}[allowframebreaks,noframenumbering]
\frametitle{Bibliographie}
%\nocite{}
\printbibliography[heading=none]
\end{frame}


\end{document}